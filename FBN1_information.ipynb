{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppktstore.registry import configure_phenopacket_registry\n",
    "from ppktstore.model import DefaultPhenopacketStore\n",
    "from ppktstore.release.stats import PPKtStoreStats\n",
    "import phenopackets as ppkt\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import cohort via phenopacket-store-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppkt2synergy import CohortManager\n",
    "phenopackets = CohortManager.from_ppkt_store(cohort_name='FBN1', ppkt_store_version=\"0.1.23\")\n",
    "print(phenopackets[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patients by FBN1: {len(phenopackets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def diseases_count_table(phenopackets:typing.List[ppkt.Phenopacket]) -> typing.Dict[str, int]:\n",
    "    \"\"\" \n",
    "    Returns:\n",
    "        A dictionary with key=disease label and value=number of phenopackets in the cohort with the disease\n",
    "    \"\"\"\n",
    "    diseases= []\n",
    "    for phenopacket in phenopackets:\n",
    "        if len(phenopacket.diseases) == 0:\n",
    "            raise ValueError(\"Empty disease list\")\n",
    "        if len(phenopacket.diseases) != 1:\n",
    "            print(\"Warning, number of diseases \", len(phenopacket.diseases))\n",
    "        #if len(phenopacket.diseases) == 1:\n",
    "        diseases.append(phenopacket.diseases[0].term.label)\n",
    "    return Counter(diseases)\n",
    "\n",
    "diseases_count = diseases_count_table(phenopackets)\n",
    "\n",
    "labels = list(diseases_count.keys())\n",
    "counts = list(diseases_count.values())\n",
    "\n",
    "# plot graph to show diseases and count\n",
    "plt.bar(labels, counts)\n",
    "plt.xlabel('Disease')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Disease Count by FBN1')\n",
    "plt.xticks(rotation=45, ha=\"right\") \n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom') \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HPO_count_table(phenopackets: list) -> int:\n",
    "    HPOs= list()\n",
    "    for phenopacket in phenopackets:\n",
    "        if len(phenopacket.phenotypic_features) == 0:\n",
    "            raise ValueError(\"Empty disease list\")\n",
    "        for phenotype in phenopacket.phenotypic_features:\n",
    "            HPOs.append(phenotype.type.label)\n",
    "        distribution = Counter(HPOs)\n",
    "    return len(set(HPOs)),distribution\n",
    "\n",
    "HPOs_count, distribution = HPO_count_table(phenopackets)\n",
    "print(f'Number of distinct HPOs by FBN1: {HPOs_count}')\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cohorts(\n",
    "    store: DefaultPhenopacketStore,\n",
    "    cohort_names: typing.List[str]\n",
    ") -> DefaultPhenopacketStore:\n",
    "    \"\"\"\n",
    "    Filter cohorts from a DefaultPhenopacketStore by specified cohort names.\n",
    "\n",
    "    :param store: Original DefaultPhenopacketStore instance.\n",
    "    :param cohort_names: List of cohort names to include in the new store.\n",
    "    :return: A new DefaultPhenopacketStore containing only the specified cohorts.\n",
    "    \"\"\"\n",
    "    # Filter the cohorts based on the provided list of cohort names\n",
    "    filtered_cohorts = [\n",
    "        cohort for cohort in store.cohorts() if cohort.name in cohort_names\n",
    "    ]\n",
    "\n",
    "    # Return a new DefaultPhenopacketStore with the filtered cohorts\n",
    "    return DefaultPhenopacketStore(\n",
    "        name=f\"{store.name}_filtered\",  \n",
    "        path=store.path, \n",
    "        cohorts=filtered_cohorts,  # only the filtered cohorts\n",
    "    )\n",
    "\n",
    "\n",
    "registry = configure_phenopacket_registry()\n",
    "with registry.open_phenopacket_store(release=\"0.1.22\") as ps:\n",
    "    phenopackets = filter_cohorts(\n",
    "    store=ps,  \n",
    "    cohort_names=[\"FBN1\"]  # Build a new phenopacketstore with cohort FBN1\n",
    "    )\n",
    "    stats = PPKtStoreStats(phenopackets)\n",
    "    df = stats.get_summary_df()\n",
    "    print(df.head())\n",
    "    print(f'Number of patients by FBN1: {df.shape[0]}')\n",
    "    diseases_count = stats.get_counts_per_disease_df()\n",
    "    print(f'Number of Diseases by FBN1: {diseases_count}')\n",
    "    HPOs_count = stats._get_total_and_unique_hpo_counts(phenopackets)\n",
    "    print(f'Number of distinct HPOs by FBN1: {HPOs_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CohortHPO Correlation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def get_status_for_terms(patient, hpo_id_A: str, hpo_id_B: str) -> Union[tuple, None]:\n",
    "    \"\"\"\n",
    "    Checks the statuses (observed or excluded) of two HPO term IDs in a patient's phenotype data.\n",
    "\n",
    "    Args:\n",
    "        phenotype: A PhenotypicFeature object containing the patient's phenotype data.\n",
    "        hpo_id_A: The first HPO term ID to check.\n",
    "        hpo_id_B: The second HPO term ID to check.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (status_A, status_B) where each status is:\n",
    "            - 1 if the phenotype is observed (not excluded).\n",
    "            - 0 if the phenotype is excluded.\n",
    "            - None if the HPO term is not present in the phenotype.\n",
    "    \"\"\"\n",
    "    status_A = status_B = None\n",
    "\n",
    "    for phenotype_feature in patient.phenotypic_features:\n",
    "        if phenotype_feature.type.id == hpo_id_A:\n",
    "            status_A = 0 if phenotype_feature.excluded else 1\n",
    "        elif phenotype_feature.type.id == hpo_id_B:\n",
    "            status_B = 0 if phenotype_feature.excluded else 1\n",
    "    \n",
    "        # Early stop if both statuses are found\n",
    "        if status_A is not None and status_B is not None:\n",
    "            return status_A, status_B    \n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_mcc_and_p(observed_status_A:list, observed_status_B:list)->tuple:\n",
    "    \"\"\"\n",
    "    Calculate the Matthews Correlation Coefficient (MCC) and its associated p-value using a contingency table and chi-square test.\n",
    "\n",
    "    Args:\n",
    "        observed_status_A: List of 0/1 values for variable A.\n",
    "        observed_status_B: List of 0/1 values for variable B.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mcc, p_value)\n",
    "    \"\"\"\n",
    "    contingency_table = np.array([\n",
    "        [sum((np.array(observed_status_A) == 1) & (np.array(observed_status_B) == 1)),\n",
    "         sum((np.array(observed_status_A) == 1) & (np.array(observed_status_B) == 0))],\n",
    "        [sum((np.array(observed_status_A) == 0) & (np.array(observed_status_B) == 1)),\n",
    "         sum((np.array(observed_status_A) == 0) & (np.array(observed_status_B) == 0))]\n",
    "    ])\n",
    "    chi2, p_value, _, _ = scipy.stats.chi2_contingency(contingency_table)\n",
    "    mcc = matthews_corrcoef(observed_status_A, observed_status_B)\n",
    "    return mcc, p_value\n",
    "\n",
    "\n",
    "def test_hpo_terms(cohort: str, hpo_id_A: str, hpo_id_B: str):\n",
    "    \"\"\"\n",
    "    Perform correlation tests (Spearman and MCC) between two HPO terms in a cohort of patients.\n",
    "\n",
    "    Args:\n",
    "        cohort: The name of the patient cohort to analyze.\n",
    "        hpo_id_A: The first HPO term ID to correlate.\n",
    "        hpo_id_B: The second HPO term ID to correlate.\n",
    "        url: The URL of the HPO ontology in JSON format.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing correlation coefficients and p-values for each test.\n",
    "        If the data is insufficient (< 30 samples), an error message is returned.\n",
    "    \"\"\"\n",
    "   \n",
    "    observed_status_A = []\n",
    "    observed_status_B = []\n",
    "    \n",
    "    # Import cohort\n",
    "    patients = import_cohort(cohort)\n",
    "    for patient in patients:\n",
    "        result = get_status_for_terms(patient, hpo_id_A, hpo_id_B)\n",
    "        if result is not None:\n",
    "            status_A, status_B = result\n",
    "            observed_status_A.append(status_A)\n",
    "            \n",
    "            observed_status_B.append(status_B)\n",
    "\n",
    "    # If the number of observed data points is less than 30, return an error message. \n",
    "    # This threshold ensures sufficient statistical power for reliable correlation tests.\n",
    "    if len(observed_status_A) < 30:\n",
    "        return {\"error\": \"Not enough data for correlation tests\"}\n",
    "\n",
    "    # Spearman test\n",
    "    spearman_corr, spearman_p = scipy.stats.spearmanr(observed_status_A, observed_status_B)\n",
    "\n",
    "    # MCC\n",
    "    mcc, mcc_p = calculate_mcc_and_p(observed_status_A, observed_status_B)\n",
    "\n",
    "    return {\n",
    "        \"Spearman\": {\"correlation\": spearman_corr, \"p_value\": spearman_p},\n",
    "        \"MCC\": {\"correlation\": mcc, \"p_value\": mcc_p}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phenopackets as ppkt \n",
    "import hpotk\n",
    "from ppkt2synergy import get_status_for_terms\n",
    "\n",
    "phenopkt = ppkt.Phenopacket()\n",
    "#\n",
    "shortStatureOc = ppkt.OntologyClass(id=\"HP:0004322\", label=\"Short stature\")\n",
    "microcephalyOc = ppkt.OntologyClass(id=\"HP:0000252\", label=\"Microcephaly\")\n",
    "deepPhiltrumOc = ppkt.OntologyClass(id=\"HP:0002002\", label=\"Deep philtrum\")\n",
    "highPalateOc = ppkt.OntologyClass(id=\"HP:0000218\", label=\"High palate\")\n",
    "shortStaturePf = ppkt.PhenotypicFeature(type=shortStatureOc)\n",
    "microcephalyPf = ppkt.PhenotypicFeature(type=microcephalyOc)\n",
    "\n",
    "phenopkt.phenotypic_features.append(shortStaturePf)\n",
    "phenopkt.phenotypic_features.append(microcephalyPf)\n",
    "#phenopkt.phenotypic_features.append(deepPhiltrum)\n",
    "#phenopkt.phenotypic_features.append(highPalate)\n",
    "\n",
    "\n",
    "get_status_for_terms(phenopkt, shortStatureOc.id, microcephalyOc.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpotk\n",
    "import pandas as pd\n",
    "\n",
    "def generate_hpo_term_status_matrix(cohort: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a binary matrix of HPO term statuses for all patients in a cohort.\n",
    "\n",
    "    Args:\n",
    "        cohort: The patient cohort, a collection of patient objects with phenotypic features.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame:\n",
    "            - Rows represent patients (indexed by their IDs).\n",
    "            - Columns represent unique HPO IDs (sorted alphabetically).\n",
    "            - Values are binary (1: observed, 0: excluded).\n",
    "    \"\"\"\n",
    "\n",
    "    patients = import_cohort(cohort)\n",
    "    hpo_ids = set()\n",
    "    status_data = {}\n",
    "\n",
    "    # Single pass to collect HPO IDs and patient statuses\n",
    "    for patient in patients:\n",
    "        status_data[patient.id] = {}\n",
    "        for feature in patient.phenotypic_features:\n",
    "            hpo_id = feature.type.id\n",
    "            hpo_ids.add(hpo_id)\n",
    "            status_data[patient.id][hpo_id] = 0 if feature.excluded else 1\n",
    "\n",
    "    # Create a sorted list of unique HPO IDs\n",
    "    hpo_ids = sorted(hpo_ids)\n",
    "\n",
    "    # Convert the status_data dictionary to a DataFrame\n",
    "    status_matrix = pd.DataFrame.from_dict(status_data, orient='index', columns=hpo_ids)\n",
    "\n",
    "    return status_matrix\n",
    "\n",
    "\n",
    "\n",
    "def find_unrelated_hpo_terms(\n",
    "        hpo_id: str, \n",
    "        cohort:str, \n",
    "        url= 'https://github.com/obophenotype/human-phenotype-ontology/releases/download/v2023-10-09/hp.json') -> dict:\n",
    "    \"\"\"\n",
    "    Check if a given HPO ID  exists in the filtered terms_status DataFrame, where columns (HPO terms) with more than 50% missing values are removed.\n",
    "    If it exists, return unrelated terms (terms not ancestors, descendants, or the term itself).\n",
    "    If the term is not found, notify the user.\n",
    "\n",
    "    Args:\n",
    "        term: The HPO ID to check.\n",
    "        cohort: The patient cohort to be analyzed.\n",
    "        url: The URL or path to load the HPO ontology in JSON format.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with 'status' indicating success or failure, and 'data' containing the unrelated terms\n",
    "        or a failure message.\n",
    "    \"\"\"\n",
    "    # Load the HPO ontology\n",
    "    hpo = hpotk.load_minimal_ontology(url)\n",
    "    terms_status = generate_hpo_term_status_matrix(cohort)\n",
    "    \n",
    "    # Remove columns with None values exceeding 50%\n",
    "    terms_status = terms_status.loc[:, terms_status.isna().mean() <= 0.5]\n",
    "\n",
    "    # Check if the term exists in the filtered terms_status\n",
    "    if hpo_id not in terms_status.columns:\n",
    "        return {\n",
    "            \"error\": f\"The HPO term '{hpo_id}' was not found. It might not be relevant to this cohort or was excluded because it appears in less than 50% of patients. Please check the term and its applicability.\"\n",
    "\n",
    "        }\n",
    "\n",
    "    # Get ancestors and descendants of the term\n",
    "    ancestors = hpo.graph.get_ancestors(hpo_id)\n",
    "    descendants = hpo.graph.get_descendants(hpo_id)\n",
    "\n",
    "    # Get unrelated terms\n",
    "    related_terms = set(ancestors) | set(descendants) | {hpo_id}\n",
    "    unrelated_terms = [col for col in terms_status.columns if col not in related_terms]\n",
    "\n",
    "    return unrelated_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = find_unrelated_hpo_terms(\"HP:0001634\",'FBN1')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_hpo_terms('FBN1', 'HP:0001634', 'HP:0001382')\n",
    "print(results)\n",
    "results = test_hpo_terms('FBN1', 'HP:0001634', 'HP:0000098')\n",
    "print(results)\n",
    "results = test_hpo_terms('FBN1', 'HP:0001634', 'HP:0000218')\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
